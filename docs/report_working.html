<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Andrea Plumbley">

<title>PLMAND002 - Assignment 1: Report</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PLMAND002</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./report_working.html" aria-current="page">
 <span class="menu-text">Assignment 1: Report</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./Appendix.html">
 <span class="menu-text">Appendix</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review">Literature Review</a></li>
  <li><a href="#data-cleaning-tokenization-and-exploration" id="toc-data-cleaning-tokenization-and-exploration" class="nav-link" data-scroll-target="#data-cleaning-tokenization-and-exploration"><u>Data Cleaning, Tokenization, and Exploration</u></a></li>
  <li><a href="#data-input-structures" id="toc-data-input-structures" class="nav-link" data-scroll-target="#data-input-structures"><u>Data Input Structures</u></a></li>
  <li><a href="#training-validation-and-test-splits" id="toc-training-validation-and-test-splits" class="nav-link" data-scroll-target="#training-validation-and-test-splits">Training, Validation and Test Splits</a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods"><u>Methods</u></a>
  <ul class="collapse">
  <li><a href="#classification-tree" id="toc-classification-tree" class="nav-link" data-scroll-target="#classification-tree">Classification Tree</a></li>
  <li><a href="#boosting---tree-based-method" id="toc-boosting---tree-based-method" class="nav-link" data-scroll-target="#boosting---tree-based-method">Boosting - Tree Based Method</a></li>
  <li><a href="#feed-forward-neural-network" id="toc-feed-forward-neural-network" class="nav-link" data-scroll-target="#feed-forward-neural-network">Feed-Forward Neural Network</a></li>
  <li><a href="#convolutional-neural-network" id="toc-convolutional-neural-network" class="nav-link" data-scroll-target="#convolutional-neural-network">Convolutional Neural Network</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><u>Results</u></a>
  <ul class="collapse">
  <li><a href="#classification-tree-1" id="toc-classification-tree-1" class="nav-link" data-scroll-target="#classification-tree-1">Classification Tree</a></li>
  <li><a href="#boosted-trees" id="toc-boosted-trees" class="nav-link" data-scroll-target="#boosted-trees">Boosted Trees</a></li>
  <li><a href="#feed-forward-neural-network-1" id="toc-feed-forward-neural-network-1" class="nav-link" data-scroll-target="#feed-forward-neural-network-1">Feed-Forward Neural Network</a></li>
  <li><a href="#convolutional-neural-network-1" id="toc-convolutional-neural-network-1" class="nav-link" data-scroll-target="#convolutional-neural-network-1">Convolutional Neural Network</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a>
  <ul class="collapse">
  <li><a href="#which-type-of-predictive-model-had-most-satisfactory-results" id="toc-which-type-of-predictive-model-had-most-satisfactory-results" class="nav-link" data-scroll-target="#which-type-of-predictive-model-had-most-satisfactory-results">Which type of predictive model had most satisfactory results</a></li>
  <li><a href="#which-input-data-structure-seemed-to-be-best" id="toc-which-input-data-structure-seemed-to-be-best" class="nav-link" data-scroll-target="#which-input-data-structure-seemed-to-be-best">Which input data structure seemed to be best</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Assignment 1: Report</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Andrea Plumbley </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>The aim of this assignment is to ‘predict the president’, to build predictive models that take in a sentence of text from a speech and predict which South African president said it. The data set given is a collection of 36 State of the Nation Addresses (SONA) in South Africa, delivered between 1994 and 2022. The assignment focuses on text mining and manipulation as well as predictive models, particularly focusing on neural networks and their classification performance. Before unpacking the data, a brief literature review is first given. Following this the data cleaning and exploration will be detailed and key features of the data discussed. The methods to format the data as well as the training, validation and test data splits will be outlined. The methods used to construct the different predictive models will then be detailed. Following this, results of the different predictive models will be presented and discussed and final conclusions made.</p>
</section>
<section id="literature-review" class="level2">
<h2 class="anchored" data-anchor-id="literature-review">Literature Review</h2>
<p>A brief summary of the literature on text classification techniques is now presented.</p>
</section>
<section id="data-cleaning-tokenization-and-exploration" class="level2">
<h2 class="anchored" data-anchor-id="data-cleaning-tokenization-and-exploration"><u>Data Cleaning, Tokenization, and Exploration</u></h2>
<p>The data that is used in this particular problem are the State of the Nation Addresses in South Africa from 1994 to 2022. There a 36 speeches given by 6 different presidents, namely Mandela, de Klerk, Mbkei, Zuma, Motlanthe and Ramaphosa. The initial steps in the solving the predict the president problem is to break the speeches up into their individual sentences and remove any unwanted characters, numbers or punctuation marks. The speeches were tokenized, broken up into smaller parts, using the unnest_tokens function in R. Each speech was split up into its sentences and the new data structure included the sentence along with the president who said it. For modelling purposes the sentences need to be only made up of their words so that when each sentence is tokenized into words, punctuation marks and numbers are not recognized as individual words. In order to do this the str_replace_all() function in the stringr package was used in order to remove any unwanted characters which were specified using a regular expression (regex). Number, commas, question marks and exclamation marks are some examples of the characters that were removed from analysis.</p>
<p>Some exploration is required to check how imbalanced the classes are in terms of how many sentences are linked with each president. Table 1 below indicates the number of sentences associated with each president. It is clear that de Klerk and Motlanthe have much fewer associated sentences, this is expected as each of them only delivered one speech. Because of this large discrepancy in number of sentences, de Klerk and Motlanthe are removed from the analysis. The remaining four classes are still imbalanced with Mandela having the fewest sentences with 1665. To account for this all classes are made to have 1665 sentences and this is done by sampling without replacement 1665 sentences from the remaining three presidents: Mbeki, Zuma and Ramaphosa.</p>
<p><u><em>Table 1: Number of sentences by each president.</em></u></p>
<table class="table">
<thead>
<tr class="header">
<th>de Klerk</th>
<th>Mandela</th>
<th>Mbeki</th>
<th>Motlanthe</th>
<th>Ramaphosa</th>
<th>Zuma</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>97</td>
<td>1665</td>
<td>2419</td>
<td>266</td>
<td>2286</td>
<td>2656</td>
</tr>
</tbody>
</table>
<p>Having split the speeches up into sentences and removed the unwanted characters and balancing the number of sentences per president, each sentence could then be tokenized into its individual words. The sentences need to be broken down into words in order to create bag of words data structures which will be used in the predictive models.</p>
<div class="cell">

</div>
<p>Again the unnest_tokens() function is used to break the sentences up into words where each word is now associated with a president and sentence number in order to keep track of which words belong in which sentences and who said them.</p>
<p>Because many of the presidents all use common words throughout their speeches, these words need to be removed from the analysis because they do not help one to differentiate one president from another. These words are referred to as stop words and include words such as: the, and, if, them, etc. A stop_words dictionary exists which was used to remove these words from the analysis.</p>
<div class="cell" data-messages="false">
<div class="cell-output cell-output-stderr">
<pre><code>Joining with `by = join_by(word)`
Joining with `by = join_by(sentence_ID)`</code></pre>
</div>
</div>
<p>We can consider the top words each presidents says as this will likely be used as one of the input data structures. Figure 1 displays the top 10 words said by each president. From this it is clear that there is significant overlap between presidents with words such as government, south and people being said by all presidents. There are however some words that are said many times by each president that do not appear in other presidents top 10 words. For example Zuma says compatriots many times and Ramaphosa refers frequently to the economy while others do not do so as frequently. These differences in the frequent words may be useful when deciding on the different data input structures to use in the predictive models.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="data-input-structures" class="level2">
<h2 class="anchored" data-anchor-id="data-input-structures"><u>Data Input Structures</u></h2>
<p>The text data needs to be put into a specific format for the predictive models for which we use a bag of words with counts and TFIDF values. In a bag of words model a document (in this case working with sentences) is represented by the set of words used in it (REFERENCE). In this case each row of the bag of words data frame represents a sentence where the columns are the possible words used. The number of columns is very large because all words used by all presidents, excluding the stop words or other words ‘cleaned away’, are represented on the columns. The matrix is relatively sparse in that for each row (sentence) only a couple columns have values due to only a few words being used in each sentence. The values are counts of how many times each word was used in each sentence. This format is the first type of input data structure use in the predictive models.</p>
<p>The second input structure used in the predictive models is similar in format to the above except that instead of the values being counts of each word in each sentence, the value is a TFIDF value. A TFIDF (Term-frequency-inverse-document-frequency) value is a way of distinguishing which words are more or less ‘important’ in the delivered speeches. This value is made up of two calculations:</p>
<ul>
<li><p>The term frequency (tf) which is the number of times a specific terms appears in a document, divided by the number of terms in that document.</p></li>
<li><p>The inverse document frequency (idf) which is a measure of how many documents contain the specific terms and is calculated as the log of the total number of documents divided by the number of documents containing the specific word.</p></li>
</ul>
<p>The TFIDF value for a word is the product of the tf and idf measures. This data structure thus contains all the words as columns, the sentences as the rows (made up of different words) and the values in each cell are the TFIDF values. This data input structure may be more beneficial than the bag of words counts because it gives more information in terms of the relative importance or significance of the different words used in different sentences.</p>
<p>An additional way of varying the input structure which also helps reduce the dimensions of input data is to use only the top 200 most frequent words used by each president. This will help see if using more frequently used words helps better identify which president is speaking. As seen in the initial data exploration of each presidents top 10 words, there may however be significant overlap in each presidents most frequently used words and so this may not be an effective way of improving the predictions. However there maybe be unique words that each president says often that help differentiate them from one another. The top 200 words format is similar to the bag of words format in that the columns are words that make up each presidents most repeated words and the rows represent the sentences. Both counts and TFIDF scores will be used in the 200 top words data input format.</p>
<p>The above differing formats result in four different types of format of input data, two are what will be referred to as ‘all words’ formats which contain all the words except for those removed in cleaning. The one ‘all words’ format uses counts of word so form a bag of words model and the other ‘all words’ format uses TFIDF scores. The two ‘200 words’ input formats refer to those inputs that use only the top 200 most repeated words from each president. Again, one of these uses word counts and the other uses TFIDF values.</p>
<div class="cell">

</div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Joining with `by = join_by(sentence_ID)`
Joining with `by = join_by(sentence_ID)`</code></pre>
</div>
</div>
</section>
<section id="training-validation-and-test-splits" class="level2">
<h2 class="anchored" data-anchor-id="training-validation-and-test-splits">Training, Validation and Test Splits</h2>
<p>Having constructed the required data formats for the predictive model, the data must be split into training, validation and test sets before the predictive models are built. The split that will be used here is 60% training, 30% validation and 10% test data. The data splits are done grouping by president so that the classes of each president are balance in training , validation and test sets.</p>
<p>The seed was set to 2023 to ensure reproducibility. The training, validation and test sets were created by sampling from the sentence_ID variable and using this along with the anti_join() function to create the associated training, validation and test set vector of indices. For the different data formats, eg bag of words with counts versus TFIDF, the training data was created by selecting those rows where the sentence_ID variable matches those IDs in the training set vector of indices.</p>
<p>The training set will be used to build the different predictive models. The validation set will be used to select which hyper-parameters or model configuration to use. The test set will provide a final measure of performance of the selected model.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Joining with `by = join_by(sentence_ID)`
Joining with `by = join_by(sentence_ID)`</code></pre>
</div>
</div>
<div class="cell">

</div>
</section>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods"><u>Methods</u></h2>
<p>Having outlined the various data input structures that will be considered in the models as well as how the data has been split into its training, validation and testing classes, the predictive models that are used are now outlined and methods to implement them explained.</p>
<section id="classification-tree" class="level3">
<h3 class="anchored" data-anchor-id="classification-tree">Classification Tree</h3>
<p>The first predictive model applied to the data is a simple classification tree. A classification tree is a decision tree that parititions the data on different variables in order to categorize each observation into a class. In this case a classification tree would take a sentence and based on the word counts or TFIDF counts, classify the sentence as being from one of the four presidents.</p>
<p>A classification tree was fit using the rpart() function in R. Four models were fit, one on each of the four training data sets which are the full bag-of-words counts data, the full TFIDF data, the top 200 bag of words count data and the top 200 TFIDF data. The ‘method’ argument was set to ‘class’ because the response is categorical. The remaining arguments of the rpart() function were left at the default settings. For the classification tree model, no tuning was performed.</p>
</section>
<section id="boosting---tree-based-method" class="level3">
<h3 class="anchored" data-anchor-id="boosting---tree-based-method">Boosting - Tree Based Method</h3>
<p>The second predictive model that was fit was boosted trees. This is an ensemble learning method and follows on from a simple classification tree. The boosting algorithm iteratively builds decision trees where each subsequent tree learns from previous trees mistakes and so the model gradually improves.</p>
<p>To fit the boosted tree the gbm() function from the gbm package was used in R. The formula was the same as in the case of the classfication tree, predicting the president based on the bag of words and TFIDF data. For the input data structures that used only the top 200 words of each president, the number of trees was set to 500. However the input data structure with all words was much larger and took much longer to fit and so only 10 trees were used for this large data set. The interaction.depth was set to 2, shrinkage to 0.01 and bag.fraction to 1 for all models. The remaining parameters were left at the default settings.</p>
</section>
<section id="feed-forward-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="feed-forward-neural-network">Feed-Forward Neural Network</h3>
<p>A standard feed-forward neural network was fit to the different data types to predict the president who delivered the sentence. Here a number of different configurations of neural networks, with different numbers of layers and nodes were constructed and the validation set used to select the best model.</p>
<p>There are many architectures, or configurations, that can be done by varying the number of layers in the network, number of nodes per layers and other parameters such as learning rate and activation functions. The selection or ‘tuning’ of these parameters is done manually by fitting 3 different neural networks using the training data and selecting the optimal architecture based on the validation set performance. The differing configurations will be fit on the four different input data structures.</p>
<p>The keras package was used to train and fit the neural networks, making use of the keras_model_sequential(), compile() and fit() functions as well as various functions used to specify hidden layers, output layers and dropout.</p>
<p>There were a number of parameters that were common across all 3 network architectures. The output layer for all networks had 4 nodes, corresponding to the one-hot encoding of the 4 presidents. The activation function on the output layer was set to “softmax” due to the categorical nature of the response variable. The “adam” optimizer was used and categorical crossentropy specified as the error measure. In terms of fitting the model with the fit() function in keras, 30 epochs over the data were done and the batch size was set to 200 observations.</p>
<p>The differences in the configurations considered were the following:</p>
<p><strong>Neural Network 1:</strong> The first neural network was the ‘simplest’ model out of the three. This model had 1 hidden layer containing 50 nodes. The “Relu” activation function was specified on the hidden layer.</p>
<p><strong>Neural Network 2:</strong> The second network contained 3 hidden layers with 50, 10 and 5 nodes per layer respectively. “tanh” activation functions were used on each of these hidden layers.</p>
<p><strong>Neural Network 3:</strong> The third network contained 2 hidden layers with a dropout layer between the 2 hidden layers. The first layer contained 500 nodes while the second hidden layer contained 20 nodes. The dropout layer was between these two layers and a rate of 0.25 was specified.</p>
<p>These models were fit to the data input structures with all words, which had an input argument in the first layer specified at 9085 because there were 9085 columns in the bag of words data input structure. When fitting these models to the bag of words for only the top 200 words per president this input argument for the first layer was set to 378, the number of columns in that data input structure.</p>
</section>
<section id="convolutional-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-network">Convolutional Neural Network</h3>
<p>The final predictive model considered for this problem is a convolutional neural network. A convolutional neural network is a more advanced model than a standard neural network and makes use of convolution and pooling isteps n order to fit the model. This type of model is usually suited to problems such as image classification as the convolutional layers make use of filters which can ‘summarize’ the data in that way extract key features.</p>
<p>The convolutional neural network required a slightly different input format to the four data structure formats used above. For the CNNs, word embeddings are used to represent the speech sentences more directly, instead of using the bag of words format as before. Word embeddings are a way of representing words as numbers which are then fed into the model. This is done using the text_tokenizer() and texts_to_sequences() functions in R which populate the new data in terms of the embeddings. The maximum length is set to 15 which makes all sentence of length 15 and pads those sentences that are too short using the pad_sequences() function. Once sentences have been transformed in this way they can be used in the CNN model. Hence for this predictive model only one format of input data is being tested. The training, validation and test data sets still represent the same sentences as before but embedding makes them look different.</p>
<p>Two different architectures of convolutional neural network were fitted to the data in order to make predictions. The first layer of both networks is an embedding layer which is required as a result of the word embedding for the data. The last layer, as in the case of the feed forward neural network, is a layer with 4 nodes and a “softmax” activation function. The remaining network specifications are as follows:</p>
<p><strong>CNN 1:</strong> Following the first layer a dropout layer is specified with a rate of 0.2. A convolutional layer is then specified with 64 filters with kernel_size set to 8 and “relu” activation used. A pooling layer with a pool_size of 2 is then specified. After flattening, a ‘normal’ hidden layer with 300 nodes and “relu” activation is specified.</p>
<p><strong>CCN 2:</strong> Following the first layer a dropout layer with a rate of 0.1 is specified. A convolutional layer with 36 filters and a kernel_size set to 6 is then specified, with a “tanh” activation function. The pooling layer is the same as CCN 1 with a pool_size of 2. The final hidden layer, after flattening, has 100 hidden nodes and a “tanh” activation function.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results"><u>Results</u></h2>
<p>Having outlined the methods and models implemented, the results of these models are now given. For each of the models, where apllicable, the classification accuracy of the models are given in terms of the validation data set. If different configurations of the models have been presented the model with the best validation accuracy is selected and the test set then applied to this model to obtain a final measure of classification accuracy.</p>
<section id="classification-tree-1" class="level3">
<h3 class="anchored" data-anchor-id="classification-tree-1">Classification Tree</h3>
<p>The results of the classification tree fit to the four different data input structures is given in Table 2 below. This table specifies the classification accuracy for both training and test sets. The validation set was not used here because no tuning was performed so no ‘best’ model was required to be selected. From the results it is clear that the classification tree does very poorly at classifying which president said each sentence with the model only being a slight improvement from one just randomly choosing a president (25%). The classification tree performs badly on all four data input structures and for this model the different input structures to do not improve the accuracy significantly.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Classification Tree Results:</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="do">## CT 1 - All Words - BoW Counts</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>training_all_BAG <span class="ot">=</span> <span class="fu">cbind</span>(Y_train_all_BAG, X_train_all_BAG)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>fit_all_BAG <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Y_train_all_BAG <span class="sc">~</span> ., training_all_BAG, <span class="at">method =</span> <span class="st">'class'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(fit_all_BAG, main = 'Full Classification Tree')</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#text(fit_all_BAG, use.n = TRUE, all = TRUE, cex=.8)</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>fittedtrain <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_all_BAG, <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>predtrain <span class="ot">&lt;-</span> <span class="fu">table</span>(training_all_BAG<span class="sc">$</span>Y_train_all_BAG, fittedtrain)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>predtrain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           fittedtrain
            Mandela Mbeki Ramaphosa Zuma
  Mandela         0    31       961    0
  Mbeki           0    77       934    2
  Ramaphosa       0     1       982    0
  Zuma            0     8       919   55</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>accuracy_all_BAG_train <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtrain))<span class="sc">/</span><span class="fu">sum</span>(predtrain), <span class="dv">3</span>) <span class="co"># training accuracy</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fittedtest <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_all_BAG, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_test_all_BAG, X_test_all_BAG), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>predtest <span class="ot">&lt;-</span> <span class="fu">table</span>(Y_test_all_BAG, fittedtest)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>predtest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              fittedtest
Y_test_all_BAG Mandela Mbeki Ramaphosa Zuma
     Mandela         0     7       162    0
     Mbeki           0    15       151    0
     Ramaphosa       0     0       160    0
     Zuma            0     5       153    9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>accuracy_all_BAG_test <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtest))<span class="sc">/</span><span class="fu">sum</span>(predtest), <span class="dv">3</span>) <span class="co"># test accuracy </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="do">## CT 2 - All Words - TFIDF</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>training_all_TFIDF <span class="ot">=</span> <span class="fu">cbind</span>(Y_train_all_tfidf, X_train_all_tfidf)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>fit_all_TFIDF <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Y_train_all_tfidf <span class="sc">~</span> ., training_all_TFIDF, <span class="at">method =</span> <span class="st">'class'</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(fit_all_BAG, main = 'Full Classification Tree')</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#text(fit_all_BAG, use.n = TRUE, all = TRUE, cex=.8)</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>fittedtrain <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_all_TFIDF, <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>predtrain <span class="ot">&lt;-</span> <span class="fu">table</span>(training_all_TFIDF<span class="sc">$</span>Y_train_all_tfidf, fittedtrain)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>predtrain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           fittedtrain
            Mandela Mbeki Ramaphosa Zuma
  Mandela         0    31       961    0
  Mbeki           0    77       934    2
  Ramaphosa       0     1       982    0
  Zuma            0     8       919   55</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>accuracy_all_TFIDF_train <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtrain))<span class="sc">/</span><span class="fu">sum</span>(predtrain), <span class="dv">3</span>) <span class="co"># training accuracy</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>fittedtest <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_all_TFIDF, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_test_all_tfidf, X_test_all_tfidf), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>predtest <span class="ot">&lt;-</span> <span class="fu">table</span>(Y_test_all_tfidf, fittedtest)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>predtest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                fittedtest
Y_test_all_tfidf Mandela Mbeki Ramaphosa Zuma
       Mandela         0     7       162    0
       Mbeki           0    15       151    0
       Ramaphosa       0     0       160    0
       Zuma            0     5       153    9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>accuracy_all_TFIDF_test <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtest))<span class="sc">/</span><span class="fu">sum</span>(predtest), <span class="dv">3</span>) <span class="co"># test accuracy </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="do">## CT 3 - 200 Words - BoW Counts</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>training_200_BAG <span class="ot">=</span> <span class="fu">cbind</span>(Y_train_200_BAG, X_train_200_BAG)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>fit_200_BAG <span class="ot">&lt;-</span> <span class="fu">rpart</span>(training_200_BAG<span class="sc">$</span>Y_train_200_BAG <span class="sc">~</span> ., <span class="at">data =</span>  training_200_BAG, <span class="at">method =</span> <span class="st">'class'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_200_BAG, <span class="at">main =</span> <span class="st">'Full Classification Tree'</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(fit_200_BAG, <span class="at">use.n =</span> <span class="cn">TRUE</span>, <span class="at">all =</span> <span class="cn">TRUE</span>, <span class="at">cex=</span>.<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fittedtrain <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_200_BAG, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_train_200_BAG, X_train_200_BAG), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>predtrain <span class="ot">&lt;-</span> <span class="fu">table</span>(training_200_BAG<span class="sc">$</span>Y_train_200_BAG, fittedtrain)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>predtrain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           fittedtrain
            Mandela Mbeki Ramaphosa Zuma
  Mandela         0    31       900    0
  Mbeki           0    77       893    2
  Ramaphosa       0     1       934    0
  Zuma            0     8       848   55</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>accuracy_200_BAG_train <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtrain))<span class="sc">/</span><span class="fu">sum</span>(predtrain), <span class="dv">3</span>) <span class="co"># training accuracy</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>fittedtest <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_200_BAG, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_test_200_BAG, X_test_200_BAG), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>predtest <span class="ot">&lt;-</span> <span class="fu">table</span>(Y_test_200_BAG, fittedtest)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>predtest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              fittedtest
Y_test_200_BAG Mandela Mbeki Ramaphosa Zuma
     Mandela         0     7       156    0
     Mbeki           0    15       141    0
     Ramaphosa       0     0       150    0
     Zuma            0     5       145    9</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>accuracy_200_BAG_test <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtest))<span class="sc">/</span><span class="fu">sum</span>(predtest), <span class="dv">3</span>) <span class="co"># test accuracy </span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="do">## CT 4 - 200 Words - TFIDF</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>training_200_TFIDF <span class="ot">=</span> <span class="fu">cbind</span>(Y_train_200_tfidf, X_train_200_tfidf)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>fit_200_TFIDF <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Y_train_200_tfidf <span class="sc">~</span> ., training_200_TFIDF, <span class="at">method =</span> <span class="st">'class'</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_200_TFIDF, <span class="at">main =</span> <span class="st">'Full Classification Tree'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(fit_200_TFIDF, <span class="at">use.n =</span> <span class="cn">TRUE</span>, <span class="at">all =</span> <span class="cn">TRUE</span>, <span class="at">cex=</span>.<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-10-2.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>fittedtrain <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_200_TFIDF, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_train_200_tfidf, X_train_200_tfidf), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>predtrain <span class="ot">&lt;-</span> <span class="fu">table</span>(training_200_TFIDF<span class="sc">$</span>Y_train_200_tfidf, fittedtrain)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>predtrain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           fittedtrain
            Mandela Mbeki Ramaphosa Zuma
  Mandela         0    31       900    0
  Mbeki           0    77       893    2
  Ramaphosa       0     1       934    0
  Zuma            0     8       848   55</code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>accuracy_200_TFIDF_train <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtrain))<span class="sc">/</span><span class="fu">sum</span>(predtrain), <span class="dv">3</span>) <span class="co"># training accuracy</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>fittedtest <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_200_TFIDF, <span class="at">newdata =</span> <span class="fu">cbind</span>(Y_test_all_tfidf, X_test_all_tfidf), <span class="at">type =</span> <span class="st">'class'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>predtest <span class="ot">&lt;-</span> <span class="fu">table</span>(Y_test_200_tfidf, fittedtest)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>predtest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                fittedtest
Y_test_200_tfidf Mandela Mbeki Ramaphosa Zuma
       Mandela         0     7       156    0
       Mbeki           0    14       142    0
       Ramaphosa       0     1       149    0
       Zuma            0     4       148    7</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>accuracy_200_TFIDF_test <span class="ot">=</span> <span class="fu">round</span>(<span class="fu">sum</span>(<span class="fu">diag</span>(predtest))<span class="sc">/</span><span class="fu">sum</span>(predtest), <span class="dv">3</span>) <span class="co"># test accuracy </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><u><em>Table 2: Classification Accuracy of Simple Classification Tree</em></u></p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Data Input Structure</th>
<th>All BOW Counts</th>
<th>All TFIDF</th>
<th>200 Words Counts</th>
<th>200 Words TFIDF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training Classification Accuracy</td>
<td>0.281</td>
<td>0.281</td>
<td>0.284</td>
<td>0.284</td>
</tr>
<tr class="even">
<td>Test Classification Accuracy</td>
<td>0.278</td>
<td>0.278</td>
<td>0.277</td>
<td>0.271</td>
</tr>
</tbody>
</table>
</section>
<section id="boosted-trees" class="level3">
<h3 class="anchored" data-anchor-id="boosted-trees">Boosted Trees</h3>
<p>The boosted tree model was also applied to all four data input structures as above, however the model for the larger data input structures was varied slight for computational reasons. Table 3 below gives the validation data set classification accuracy for the four different boosted tree models.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming multinomial ...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming multinomial ...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming multinomial ...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming multinomial ...</code></pre>
</div>
</div>
<p><u><em>Table 3: Classification Accuracy of Boosted Trees</em></u></p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Data Input Structure</th>
<th>All BOW Counts</th>
<th>All TFIDF</th>
<th>200 Words Counts</th>
<th>200 Words TFIDF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Validation Classification Accuracy</td>
<td>0.308</td>
<td>0.304</td>
<td>0.438</td>
<td>0.447</td>
</tr>
</tbody>
</table>
<p>From the above table it is clear that the models that made use of the most common words (top 200 from each president) performed significantly better than those that use all words. This however was expected because the number of trees used in these models was much much larger which gave the model more tree to learn from. While the model using all words did not perform particularly well, with a classification accuracy of around on 30%, this is an improvement from the simple classification tree and is slightly better than the naive approach of guessing a president (25%).</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Using 500 trees...</code></pre>
</div>
</div>
<p>The best performing boosted tree model of the four is the top 200 words per president in the TFIDF format, with a classification accuracy of 0.447. Applying the test set to this model, one obtains a classification accuracy of 0.435. This is the final classification accuracy from the best model of the boosted trees predictive model. While this is not a good classification accuracy, it is better than the naive model by around 20%.</p>
</section>
<section id="feed-forward-neural-network-1" class="level3">
<h3 class="anchored" data-anchor-id="feed-forward-neural-network-1">Feed-Forward Neural Network</h3>
<p>The third predictive model used for this problem was the standard feed-forward neural network. As discussed in the methods section, three different architectures of networks were tested here on the four different data input structures. Table 4 below gives the validation data set classification accuracy for the different network architectures for the different data input structures.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_1 (Dense)                    (None, 50)                      454300      
 dense (Dense)                      (None, 4)                       204         
================================================================================
Total params: 454504 (1.73 MB)
Trainable params: 454504 (1.73 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.3663 - accuracy: 0.5607 - 71ms/epoch - 7ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 2.2444 - accuracy: 0.5390 - 64ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_1"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_5 (Dense)                    (None, 50)                      454300      
 dense_4 (Dense)                    (None, 10)                      510         
 dense_3 (Dense)                    (None, 5)                       55          
 dense_2 (Dense)                    (None, 4)                       24          
================================================================================
Total params: 454889 (1.74 MB)
Trainable params: 454889 (1.74 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.4498 - accuracy: 0.5280 - 67ms/epoch - 7ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.9091 - accuracy: 0.5108 - 70ms/epoch - 7ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_2"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_8 (Dense)                    (None, 500)                     4543000     
 dropout (Dropout)                  (None, 500)                     0           
 dense_7 (Dense)                    (None, 20)                      10020       
 dense_6 (Dense)                    (None, 4)                       84          
================================================================================
Total params: 4553104 (17.37 MB)
Trainable params: 4553104 (17.37 MB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 2.0155 - accuracy: 0.5567 - 113ms/epoch - 11ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 3.3024 - accuracy: 0.5385 - 116ms/epoch - 12ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_10 (Dense)                   (None, 50)                      18950       
 dense_9 (Dense)                    (None, 4)                       204         
================================================================================
Total params: 19154 (74.82 KB)
Trainable params: 19154 (74.82 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: nan - accuracy: 0.4438 - 52ms/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-13-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.2166 - accuracy: 0.4907 - 51ms/epoch - 5ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_4"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_14 (Dense)                   (None, 50)                      18950       
 dense_13 (Dense)                   (None, 10)                      510         
 dense_12 (Dense)                   (None, 5)                       55          
 dense_11 (Dense)                   (None, 4)                       24          
================================================================================
Total params: 19539 (76.32 KB)
Trainable params: 19539 (76.32 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: nan - accuracy: 0.4524 - 55ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-13-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.3549 - accuracy: 0.4504 - 56ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 dense_17 (Dense)                   (None, 500)                     189500      
 dropout_1 (Dropout)                (None, 500)                     0           
 dense_16 (Dense)                   (None, 20)                      10020       
 dense_15 (Dense)                   (None, 4)                       84          
================================================================================
Total params: 199604 (779.70 KB)
Trainable params: 199604 (779.70 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-13-4.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: nan - accuracy: 0.4635 - 57ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: nan - accuracy: 0.4504 - 14ms/epoch - 1ms/step</code></pre>
</div>
</div>
<p><u><em>Table 4: Validation Set Classification Accuracy of Neural Networks</em></u></p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Data Input Structure</th>
<th>All BOW Counts</th>
<th>All TFIDF</th>
<th>200 Words Counts</th>
<th>200 Words TFIDF</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NN1 Validation Classification Accuracy</td>
<td>0.5390428</td>
<td>0.5607053</td>
<td>0.4906801</td>
<td>0.4438287</td>
</tr>
<tr class="even">
<td>NN2 Validation Classification Accuracy</td>
<td>0.5108312</td>
<td>0.5279597</td>
<td>0.4503778</td>
<td>0.4523929</td>
</tr>
<tr class="odd">
<td>NN3 Validation Classification Accuracy</td>
<td>0.5385391</td>
<td>0.5566751</td>
<td>0.4503778</td>
<td>0.4634761</td>
</tr>
</tbody>
</table>
<p>An improvement is seen for these neural network classification models from the boosted tree models with the models using all words having over 50% classification accuracy. In general the neural networks that use all words perform better at classifying the presidents than the models which use only the top 200 words used by each president. Comparing both input structure that use all words, it can be seen that the TFIDF input structure performs slightly better than the standard counts bag of words input data structure. In terms of the three different network architectures the best network architecture depends on the input data structure used. For the BOW counts data, the NN1 and NN3 have almost the same accuracy with NN2 slightly lower. For the TFIDF data, the simplest neural network performs the best with a classification accuracy of 0.5607053. The model NN1, with TFIDF data has the highest validation set accuracy and so is selected as the best model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">50</span>, <span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">9085</span>), <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">4</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(model1)</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>model1 <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"adam"</span>,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="st">"accuracy"</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>history1<span class="fl">.1</span> <span class="ot">&lt;-</span> model1 <span class="sc">%&gt;%</span> <span class="fu">fit</span>(X_train_all_tfidf, Y_train, <span class="at">epochs =</span> <span class="dv">30</span>, <span class="at">batch_size =</span> <span class="dv">200</span>, <span class="at">verbose =</span> <span class="dv">0</span>) </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co">#plot(history1.1)</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>results_test <span class="ot">&lt;-</span> model1 <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(X_test_all_tfidf, Y_test, <span class="at">batch_size=</span><span class="dv">200</span>, <span class="at">verbose =</span> <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The test data set is applied to this model to obtain a final prediction accuracy. The classification accuracy on the test data, using TFIDF input and NN1 is 0.5694864 . While this is not a very good classification accuracy it is much better than the naive classification approach (25%) and is fairly good in terms of the accuracy seen in other models so far.</p>
</section>
<section id="convolutional-neural-network-1" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-network-1">Convolutional Neural Network</h3>
<p>The final predictive method that was considered for the predict-the-president problem was a convolutional neural network. As already discussed in the methods section, this predictive model took in a different format of the data by using word embeddings for each of the sentences instead of the bag of words model of input data. Two different architectures were used here as outlined in the methods. Table 5 below summarizes the results of the two methods.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] "south african society - in its schools and universities, in the work-place, in sports, in professional work and all areas of social interaction - needs to infuse itself with a measure of discipline, a work ethic and responsibility for the actions we undertake"</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1]]
 [1]  7  8  9  1 10 11  2 12  1  4  3 13  1 14  1 15  3  2 16 17  5 18 19 20 21
[26] 22 23 24  6 25  5 26  6  3 27  2 28 29  4 30 31 32</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>$south
[1] 7

$african
[1] 8

$society
[1] 9

$`in`
[1] 1

$its
[1] 10

$schools
[1] 11

$and
[1] 2

$universities
[1] 12

$`in`
[1] 1

$the
[1] 4

$work
[1] 3

$place
[1] 13

$`in`
[1] 1

$sports
[1] 14

$`in`
[1] 1

$professional
[1] 15

$work
[1] 3

$and
[1] 2

$all
[1] 16

$areas
[1] 17

$of
[1] 5

$social
[1] 18

$interaction
[1] 19

$needs
[1] 20

$to
[1] 21

$infuse
[1] 22

$itself
[1] 23

$with
[1] 24

$a
[1] 6

$measure
[1] 25

$of
[1] 5

$discipline
[1] 26

$a
[1] 6

$work
[1] 3

$ethic
[1] 27

$and
[1] 2

$responsibility
[1] 28

$`for`
[1] 29

$the
[1] 4

$actions
[1] 30

$we
[1] 31

$undertake
[1] 32</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_7"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 embedding (Embedding)              (None, 15, 10)                  10000       
 dropout_2 (Dropout)                (None, 15, 10)                  0           
 conv1d (Conv1D)                    (None, 8, 64)                   5184        
 max_pooling1d (MaxPooling1D)       (None, 4, 64)                   0           
 flatten (Flatten)                  (None, 256)                     0           
 dense_21 (Dense)                   (None, 300)                     77100       
 dense_20 (Dense)                   (None, 4)                       1204        
================================================================================
Total params: 93488 (365.19 KB)
Trainable params: 93488 (365.19 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-15-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.6236 - accuracy: 0.2469 - 64ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_8"
________________________________________________________________________________
 Layer (type)                       Output Shape                    Param #     
================================================================================
 embedding_1 (Embedding)            (None, 15, 10)                  10000       
 dropout_3 (Dropout)                (None, 15, 10)                  0           
 conv1d_1 (Conv1D)                  (None, 10, 36)                  2196        
 max_pooling1d_1 (MaxPooling1D)     (None, 5, 36)                   0           
 flatten_1 (Flatten)                (None, 180)                     0           
 dense_23 (Dense)                   (None, 100)                     18100       
 dense_22 (Dense)                   (None, 4)                       404         
================================================================================
Total params: 30700 (119.92 KB)
Trainable params: 30700 (119.92 KB)
Non-trainable params: 0 (0.00 Byte)
________________________________________________________________________________</code></pre>
</div>
<div class="cell-output-display">
<p><img src="report_working_files/figure-html/unnamed-chunk-15-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10/10 - 0s - loss: 1.5457 - accuracy: 0.2408 - 62ms/epoch - 6ms/step</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>4/4 - 0s - loss: 1.5515 - accuracy: 0.2538 - 10ms/epoch - 3ms/step</code></pre>
</div>
</div>
<p><u><em>Table 5: Validation Set Classification Accuracy of CNN</em></u></p>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>CNN 1</th>
<th>CNN 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Validation Classification Accuracy</td>
<td>0.2468514</td>
<td>0.240806</td>
</tr>
</tbody>
</table>
<p>It is clear that the convolutional neural network does not do well at predicting the correct classification with the validation accuracy being the same as a naive prediction guess would be. The test set accuracy for CNN2, which performs only marginally better, is: 0.2537764 which is very poor predictive performance.</p>
<div class="cell">

</div>
<div class="cell">

</div>
<div class="cell">

</div>
<p>Now lets try a cnn</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>max_features <span class="ot">&lt;-</span> <span class="dv">1000</span>        <span class="co"># choose max_features most popular words</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="ot">=</span> <span class="fu">text_tokenizer</span>(<span class="at">num_words =</span> max_features)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fit_text_tokenizer</span>(tokenizer, sona_sentences_FINAL<span class="sc">$</span>sentences[<span class="dv">4</span>])</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>sona_sentences_FINAL<span class="sc">$</span>sentences[<span class="dv">4</span>]</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>tts <span class="ot">&lt;-</span> <span class="fu">texts_to_sequences</span>(tokenizer, sona_sentences_FINAL<span class="sc">$</span>sentences[<span class="dv">4</span>])</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>tts</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>tokenizer<span class="sc">$</span>word_index[tts[[<span class="dv">1</span>]]]</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>sequences <span class="ot">=</span> tokenizer<span class="sc">$</span><span class="fu">texts_to_sequences</span>(sona_sentences_FINAL<span class="sc">$</span>sentences)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a>train_row <span class="ot">=</span> train_ids<span class="sc">$</span>sentence_ID</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>val_row <span class="ot">=</span> val_ids<span class="sc">$</span>sentence_ID</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.factor</span>(sona_sentences_FINAL<span class="sc">$</span>president_name)</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.integer</span>(y)</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>val <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>train<span class="sc">$</span>x <span class="ot">&lt;-</span> sequences[train_row]</span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>val<span class="sc">$</span>x <span class="ot">&lt;-</span>  sequences[val_row]</span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a>train<span class="sc">$</span>y <span class="ot">&lt;-</span> y[train_row]</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>val<span class="sc">$</span>y <span class="ot">&lt;-</span>  y[val_row]</span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">unlist</span>(<span class="fu">lapply</span>(sequences, length)), <span class="at">main =</span> <span class="st">"Sequence length after tokenization"</span>)</span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a>maxlen <span class="ot">&lt;-</span> <span class="dv">15</span>            </span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> train<span class="sc">$</span>x <span class="sc">%&gt;%</span> <span class="fu">pad_sequences</span>(<span class="at">maxlen =</span> maxlen)</span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> val<span class="sc">$</span>x <span class="sc">%&gt;%</span> <span class="fu">pad_sequences</span>(<span class="at">maxlen =</span> maxlen)</span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_embedding</span>(max_features, <span class="at">output_dim =</span> <span class="dv">10</span>, <span class="at">input_length =</span> maxlen) <span class="sc">%&gt;%</span></span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">100</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">4</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>)</span>
<span id="cb55-40"><a href="#cb55-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-41"><a href="#cb55-41" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb55-42"><a href="#cb55-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-43"><a href="#cb55-43" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb55-44"><a href="#cb55-44" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span id="cb55-45"><a href="#cb55-45" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"adam"</span>,</span>
<span id="cb55-46"><a href="#cb55-46" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="st">"accuracy"</span></span>
<span id="cb55-47"><a href="#cb55-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb55-48"><a href="#cb55-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-49"><a href="#cb55-49" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train,Y_train,</span>
<span id="cb55-50"><a href="#cb55-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">600</span>, <span class="at">epochs =</span> <span class="dv">30</span>, <span class="at">verbose =</span> <span class="dv">0</span>)</span>
<span id="cb55-51"><a href="#cb55-51" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>embedding_dims <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_embedding</span>(max_features, <span class="at">output_dim =</span> embedding_dims, <span class="at">input_length =</span> maxlen) <span class="sc">%&gt;%</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="fl">0.2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_1d</span>(<span class="at">filters =</span> <span class="dv">64</span>, <span class="at">kernel_size =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_1d</span>(<span class="at">pool_size =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">300</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">4</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">"adam"</span>,</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="st">"accuracy"</span></span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(x_train,Y_train,</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">batch_size =</span> <span class="dv">600</span>, <span class="at">epochs =</span> <span class="dv">30</span>, <span class="at">verbose =</span> <span class="dv">0</span>)</span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history)</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(x_test, Y_val, <span class="at">batch_size=</span><span class="dv">600</span>, <span class="at">verbose =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<section id="which-type-of-predictive-model-had-most-satisfactory-results" class="level3">
<h3 class="anchored" data-anchor-id="which-type-of-predictive-model-had-most-satisfactory-results">Which type of predictive model had most satisfactory results</h3>
</section>
<section id="which-input-data-structure-seemed-to-be-best" class="level3">
<h3 class="anchored" data-anchor-id="which-input-data-structure-seemed-to-be-best">Which input data structure seemed to be best</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>